{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1.What are the key differences between SQL and NoSQL databases?\n",
        "1. Data Model\n",
        "- SQL: Uses tables with rows and columns (structured, relational data).\n",
        "- NoSQL: Uses key-value pairs, documents, graphs, or wide-columns (non-relational, flexible structure).\n",
        "2. Schema\n",
        "- SQL: Has a fixed schema — the structure must be defined before inserting data.\n",
        "- NoSQL: Has a dynamic schema — you can store data without defining the structure first.\n",
        "3. Scalability\n",
        "- SQL: Scales vertically (add more power to a single server).\n",
        "- NoSQL: Scales horizontally (add more servers to handle data across nodes).\n",
        "4. Query Language\n",
        "- SQL: Uses Structured Query Language (SQL) to interact with the database.\n",
        "- NoSQL: Uses varied query methods, often depending on the database (e.g., MongoDB uses JSON-like queries).\n",
        "5. Transactions\n",
        "- SQL: Fully supports ACID transactions (Atomicity, Consistency, Isolation, Durability) for reliability.\n",
        "- NoSQL: May offer eventual consistency; not all NoSQL databases fully support ACID.\n",
        "6. Use Cases\n",
        "- SQL: Best for structured data and complex relationships (e.g., ERP, banking systems).\n",
        "- NoSQL: Best for unstructured or semi-structured data, big data, and real-time apps (e.g., social media, logs).\n",
        "7. Joins\n",
        "- SQL: Supports joins to relate data from multiple tables.\n",
        "- NoSQL: Generally does not support joins; uses embedded or denormalized data instead.\n",
        "8. Performance at Scale\n",
        "- SQL: Can slow down with very large datasets due to joins and normalization.\n",
        "- NoSQL: Designed for high performance and fast read/write in distributed systems.\n",
        "9. Examples\n",
        "- SQL: MySQL, PostgreSQL, Oracle, SQL Server.\n",
        "- NoSQL: MongoDB, Cassandra, CouchDB, Redis, Neo4j.\n",
        "\n",
        "\n",
        "Q2.What makes MongoDB a good choice for modern applications?\n",
        "1. Flexible Schema (Schema-less Design)\n",
        "- You can store documents with different fields and structures in the same collection.\n",
        "- Great for rapid development, where data structures might evolve frequently.\n",
        "2. JSON-like Documents (BSON Format)\n",
        "- Stores data in a format similar to JSON, which is easy to read and integrates well with JavaScript and web applications.\n",
        "- Allows for embedded/nested documents, making queries and data modeling more intuitive.\n",
        "3. High Scalability\n",
        "- MongoDB supports horizontal scaling using sharding (splitting data across multiple servers).\n",
        "- Ideal for handling large volumes of data and high-throughput workloads.\n",
        "4. Fast Performance\n",
        "- Optimized for read and write performance, especially for semi-structured or unstructured data.\n",
        "- Suitable for real-time analytics, logging systems, or rapidly growing data sets.\n",
        "5. Built-in High Availability\n",
        "- Supports replica sets (automatic failover and data redundancy).\n",
        "- Ensures fault tolerance and data consistency across multiple nodes.\n",
        "6. Rich Query Language\n",
        "- Supports powerful queries using filters, projections, aggregations, text search, and geospatial queries.\n",
        "- Enables complex operations without joins or deeply nested logic.\n",
        "7. Developer-Friendly\n",
        "-  Integrates easily with popular programming languages (JavaScript, Python, Node.js, etc.).\n",
        "- Great support through MongoDB drivers, official documentation, and Atlas cloud platform.\n",
        "8. Ideal for Modern Use Cases\n",
        "- Works well for:\n",
        " - Real-time analytics\n",
        " - IoT and mobile apps\n",
        " - Content management systems (CMS)\n",
        " - E-commerce platforms\n",
        " - Chat applications and social networks\n",
        "9. MongoDB Atlas (Cloud Platform)\n",
        "- Fully managed cloud service with:\n",
        " - Auto-scaling\n",
        " - Backups\n",
        " - Monitoring\n",
        " - Global distribution\n",
        "\n",
        "\n",
        "Q3.Explain the concept of collections in MongoDB?\n",
        "- In MongoDB, a collection is equivalent to a table in relational databases (like MySQL or PostgreSQL). It is a container for documents, which are stored in a BSON (Binary JSON) format.\n",
        "- Key Characteristics of Collections:\n",
        "1. Stores Documents\n",
        "- A collection holds documents (like rows in a table).\n",
        "- Documents are written in JSON-like format with key-value pairs.\n",
        "- {\n",
        "  - \"name\": \"Alice\",\n",
        "  - \"age\": 28,\n",
        "  - \"email\": \"alice@example.com\"\n",
        "- }\n",
        "2. No Fixed Schema\n",
        "- Unlike SQL tables, collections in MongoDB don’t require a predefined schema.\n",
        "- Each document in the same collection can have a different structure.\n",
        "- // Document 1\n",
        " - { \"name\": \"John\", \"age\": 30 }\n",
        "- // Document 2\n",
        " - { \"name\": \"Jane\", \"city\": \"Delhi\", \"hobbies\": [\"reading\", \"cycling\"] }\n",
        "3. Created Automatically\n",
        "- Collections are automatically created when you insert the first document.\n",
        "- No need for explicit CREATE TABLE like SQL.\n",
        "- db.users.insertOne({ name: \"Tom\", age: 25 }); // Creates `users` collection\n",
        "4. Can Be Indexed\n",
        "- Collections support indexes to improve query performance, just like SQL.\n",
        "- Grouped by Database\n",
        "- Collections exist inside databases.\n",
        "- One MongoDB database can have many collections.\n",
        "- db_name\n",
        "├── users (collection)\n",
        "├── orders (collection)\n",
        "└── products (collection)\n",
        "5.Common Operations on Collections\n",
        "- insertOne(), insertMany()\n",
        "- find(), updateOne(), deleteOne()\n",
        "- aggregate()\n",
        "\n",
        "\n",
        "Q4. How does MongoDB ensure high availability using replication?\n",
        "1. Replica Set: Core of MongoDB Replication\n",
        "- A replica set is a group of MongoDB servers (nodes) that maintain the same data.\n",
        "- It usually consists of:\n",
        " - 1 Primary node: handles all writes and reads (by default)\n",
        " - 1 or more Secondary nodes: replicate data from the primary\n",
        "2. Automatic Failover for High Availability\n",
        "- If the primary node goes down, MongoDB automatically:\n",
        " - Elects a new primary from the secondaries\n",
        " - Redirects traffic to the new primary\n",
        " - This ensures that the database remains available without manual intervention.\n",
        "3. Data Replication\n",
        "- Secondaries constantly sync with the primary by replaying the operation log (oplog).\n",
        "- All changes made to the primary are recorded in the oplog, and secondaries apply these changes to stay updated.\n",
        "4. Read & Write Behavior\n",
        "- Writes: Always go to the primary node.\n",
        "- Reads: By default, go to the primary, but you can configure read preferences to allow reads from secondaries (for load balancing).\n",
        "\n",
        "\n",
        "Q5. What are the main benefits of MongoDB Atlas?\n",
        "1. Fully Managed Database as a Service (DBaaS)\n",
        "- No need to install, update, or manage servers.\n",
        "- MongoDB Atlas handles patches, backups, monitoring, scaling, and performance optimization automatically.\n",
        "2. High Availability and Global Distribution\n",
        "- Atlas automatically sets up replica sets for redundancy and high availability.\n",
        "- You can deploy your database in multiple regions across cloud providers (AWS, Azure, GCP).\n",
        "- Ensures low latency and geo-failover for global apps.\n",
        "3. Automatic Scaling\n",
        "- Storage and compute scale automatically based on workload.\n",
        "- You can scale vertically (more power) or horizontally (sharding) with just a few clicks or even automatically.\n",
        "4. Built-in Security\n",
        "- Atlas provides end-to-end encryption, IP whitelisting, VPC peering, role-based access control (RBAC), and TLS/SSL.\n",
        "- Compliant with security standards like SOC 2, GDPR, HIPAA, etc.\n",
        "5. Powerful Monitoring and Performance Tools\n",
        "- Real-time dashboards for query performance, index suggestions, system health, and slow query analysis.\n",
        "- Integrated alerts and notifications for proactive monitoring.\n",
        "6. Easy Backup and Restore\n",
        "- Automated, point-in-time snapshots and backups.\n",
        "-  Allows for disaster recovery or rollback if needed.\n",
        "7. Serverless and On-Demand Options\n",
        "- Offers serverless instances where you're charged only for usage.\n",
        "- Great for unpredictable or low-volume workloads.\n",
        "8. Integration with Popular Tools and Services\n",
        "- Easily integrates with:\n",
        "- MongoDB Compass (GUI client)\n",
        "- BI connectors\n",
        "- Data Lake, Charts, and Realm (mobile backend)\n",
        "- DevOps tools like Terraform, AWS Lambda, etc.\n",
        "9. Multi-Cloud Flexibility\n",
        "- Deploy across AWS, Azure, and Google Cloud.\n",
        "- Even multi-cloud clusters (data replicated across cloud providers).\n",
        "10. Free Tier to Get Started\n",
        "- MongoDB Atlas offers a free shared cluster (M0) with:\n",
        "- 512 MB storage\n",
        "- 100 concurrent connections\n",
        "- Perfect for prototyping and learning\n",
        "\n",
        "\n",
        "Q6.What is the role of indexes in MongoDB, and how do they improve performance?\n",
        "-  What is the Role of Indexes in MongoDB?\n",
        " - Indexes in MongoDB are data structures that improve the speed and efficiency of query operations by allowing the database to find data without scanning every document in a collection.\n",
        " - They are similar to the index in a book, which helps you quickly find a topic rather than reading every page.\n",
        "- How Indexes Improve Performance\n",
        "1. Faster Query Execution\n",
        "- Without an index, MongoDB performs a collection scan (checks every document).\n",
        "With an index, MongoDB can jump directly to the documents that match the query criteria.\n",
        "2. Significantly reduces query time on large collections.\n",
        "- Efficient Filtering and Sorting\n",
        "- Indexes make queries with WHERE, SORT, or RANGE filters much faster.\n",
        "- Example:\n",
        " - db.users.find({ age: { $gt: 25 } }).sort({ name: 1 });\n",
        " - This will be slow without indexes on age or name.\n",
        "3. Support for Aggregation Pipelines\n",
        "- Aggregation stages like $match and $sort perform better with indexes.\n",
        "- Allows efficient data transformation and analytics on large datasets.\n",
        "4. Improves Performance of Join-like Operations\n",
        "- $lookup operations between collections benefit when the joined fields are indexed.\n",
        "5.Reduces Resource Usage\n",
        "- Fewer documents scanned = less CPU and memory used.\n",
        "- Helps with scalability and performance under load.\n",
        "\n",
        "\n",
        "Q7.Describe the stages of the MongoDB aggregation pipeline?\n",
        "1. $match — Filtering Data\n",
        "- Filters documents based on conditions (like SQL's WHERE).\n",
        "- Reduces the number of documents passed to the next stage.\n",
        "- { $match: { status: \"active\" } }\n",
        "2. $project — Reshaping Documents\n",
        "- Includes, excludes, or reshapes fields.\n",
        "- Can compute new fields or rename existing ones.\n",
        "- { $project: { name: 1, total: { $add: [\"$price\", \"$tax\"] } } }\n",
        "3. $group — Grouping and Aggregation\n",
        "- Groups documents by a field and applies aggregation functions.\n",
        "- Similar to SQL's GROUP BY.\n",
        "- {\n",
        "  - $group: {\n",
        "    - _id: \"$category\",\n",
        "    - totalSales: { $sum: \"$amount\" },\n",
        "    - avgPrice: { $avg: \"$price\" }\n",
        "  - }\n",
        "- }\n",
        "4. $sort — Sorting Results\n",
        "- Sorts documents by one or more fields (ascending or descending).\n",
        "- { $sort: { totalSales: -1 } }\n",
        "5. $limit — Restricting Output\n",
        "- Limits the number of documents passed to the next stage.\n",
        "- { $limit: 5 }\n",
        "6. $skip — Skipping Documents\n",
        "- Skips a specified number of documents (used for pagination).\n",
        "- { $skip: 10 }\n",
        "7. $lookup — Joining Collections\n",
        "- Performs a left outer join between documents from different collections.\n",
        "- {\n",
        "  - $lookup: {\n",
        "    - from: \"orders\",\n",
        "    - localField: \"customer_id\",\n",
        "    - foreignField: \"customer_id\",\n",
        "    - as: \"orders\"\n",
        "  - }\n",
        "- }\n",
        "8. $unwind — Flattening Arrays\n",
        "- Breaks apart arrays into separate documents (1 document per array element).\n",
        "- { $unwind: \"$items\" }\n",
        "9. $addFields — Add/Compute New Fields\n",
        "- Adds new fields or updates existing fields with computed values.\n",
        "- { $addFields: { discounted: { $subtract: [\"$price\", \"$discount\"] } } }\n",
        "10. $count — Count Documents\n",
        "- Counts the number of documents that pass through the pipeline.\n",
        "- { $count: \"total\" }\n",
        "\n",
        "\n",
        "Q8. What is sharding in MongoDB? How does it differ from replication?\n",
        "- Sharding is MongoDB’s method for horizontal scaling, where data is split and distributed across multiple servers (called shards).\n",
        "- This allows MongoDB to:\n",
        " - Handle very large datasets\n",
        " - Support high-throughput operations\n",
        " - Maintain performance as data volume grows\n",
        "- difference :\n",
        "1. Purpose\n",
        "- Sharding: Used to scale horizontally by distributing data across multiple servers.\n",
        "- Replication: Used to ensure data redundancy and high availability by copying data across servers.\n",
        "2. Data Storage\n",
        "- Sharding: Each shard stores a subset of the total data.\n",
        "- Replication: Each replica node stores a full copy of the data.\n",
        "3. Write and Read Scalability\n",
        "- Sharding: Improves write and read scalability by dividing the workload across shards.\n",
        "- Replication: Limited write scalability; all writes go to the primary node, reads can be distributed.\n",
        "4. Fault Tolerance\n",
        "- Sharding: Not designed for automatic failover by itself.\n",
        "- Replication: Provides automatic failover — if the primary fails, a secondary becomes primary.\n",
        "5. Query Routing\n",
        "- Sharding: Requires a mongos router to determine which shard to query.\n",
        "- Replication: No special router is needed; all nodes can respond (depending on role).\n",
        "6. Data Consistency\n",
        "- Sharding: Does not inherently provide redundancy — data is split, not copied.\n",
        "- Replication: Ensures data consistency and redundancy across multiple nodes.\n",
        "7. Use Case\n",
        "- Sharding: Ideal for very large datasets or high-throughput applications (e.g., analytics, IoT).\n",
        "- Replication: Ideal for disaster recovery, read-heavy apps, or ensuring uptime.\n",
        "8. Can They Be Combined?\n",
        "- Sharding: Yes, each shard can also be a replica set.\n",
        "- Replication: Yes, can be used within a sharded cluster.\n",
        "\n",
        "\n",
        "Q9. What is PyMongo, and why is it used?\n",
        "- PyMongo is the official Python driver for MongoDB, developed and maintained by MongoDB, Inc.It allows Python applications to connect to, interact with, and manipulate data in MongoDB databases.\n",
        "- Why is PyMongo Used?\n",
        " - PyMongo is used to:\n",
        "1. Connect Python to MongoDB\n",
        "- Establishes a connection to a MongoDB server or cluster using Python.\n",
        "from pymongo import MongoClient\n",
        "- client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "2. Perform CRUD Operations\n",
        "- Supports all Create, Read, Update, and Delete operations in Python.\n",
        "- #Insert\n",
        " - db.users.insert_one({\"name\": \"Alice\", \"age\": 25})\n",
        "- #Read\n",
        " - db.users.find_one({\"name\": \"Alice\"})\n",
        "- #Update\n",
        " - db.users.update_one({\"name\": \"Alice\"}, {\"$set\": {\"age\": 26}})\n",
        "- #Delete\n",
        " - db.users.delete_one({\"name\": \"Alice\"})\n",
        "3. Work with Collections and Databases\n",
        "- Easily create or access collections (tables) and databases.\n",
        "- db = client[\"my_database\"]\n",
        "- collection = db[\"my_collection\"]\n",
        "4. Support Aggregation Pipelines\n",
        "- Use MongoDB’s powerful aggregation framework in Python.\n",
        "- pipeline = [\n",
        "    - {\"$match\": {\"status\": \"active\"}},\n",
        "    - {\"$group\": {\"_id\": \"$category\", \"total\": {\"$sum\": \"$amount\"}}}\n",
        "- ]\n",
        "- db.orders.aggregate(pipeline)\n",
        "5. Handle Indexing and Performance\n",
        "- Create and manage indexes from your Python code.\n",
        "- collection.create_index(\"email\", unique=True)\n",
        "6. Work with MongoDB Atlas\n",
        "- PyMongo supports cloud-hosted MongoDB (Atlas) and allows secure connections via URI.\n",
        "\n",
        "\n",
        "Q10. What are the ACID properties in the context of MongoDB transactions?\n",
        "- What Are the ACID Properties in MongoDB Transactions?\n",
        " - ACID stands for Atomicity, Consistency, Isolation, and Durability — a set of properties that ensure reliable, safe database transactions.MongoDB fully supports ACID-compliant transactions starting from version 4.0 for replica sets and 4.2+ for sharded clusters.Here’s what each ACID property means in the context of MongoDB transactions:\n",
        "1. Atomicity\n",
        "- Definition: All operations within a transaction are executed as a single unit — either all succeed or none are applied.\n",
        "- MongoDB: Ensures multi-document transactions either fully commit or rollback if something fails.\n",
        "- Example:\n",
        " - If you're transferring money between two accounts:\n",
        "   - session.start_transaction()\n",
        "   - db.accounts.update_one({\"_id\": 1}, {\"$inc\": {\"balance\": -100}}, session=session)\n",
        "   - db.accounts.update_one({\"_id\": 2}, {\"$inc\": {\"balance\": 100}}, session=session)\n",
        "   - session.commit_transaction()\n",
        " - If any update fails, both operations are rolled back.\n",
        "2. Consistency\n",
        "- Definition: A transaction brings the database from one valid state to another, maintaining all data rules and constraints.\n",
        "- MongoDB: Enforces data types, schemas (with schema validation), and referential logic within a transaction to keep the database consistent.\n",
        "- You won’t be left with half-updated data that breaks business rules.\n",
        "3. Isolation\n",
        "- Definition: Concurrent transactions are isolated from each other — they don’t interfere or see each other’s intermediate changes.\n",
        "- MongoDB: Ensures that one transaction doesn’t affect another, even when they run at the same time.\n",
        "- E.g., While one transaction updates data, others cannot see those changes until it is committed.\n",
        "4. Durability\n",
        "- Definition: Once a transaction is committed, its changes are permanently saved, even if there’s a crash or power failure.\n",
        "- MongoDB: Writes are stored in the WiredTiger journal, ensuring changes persist.\n",
        "\n",
        "\n",
        "Q11.What is the purpose of MongoDB’s explain() function?\n",
        "-  Purpose of explain()\n",
        "Understand Query Execution Plan\n",
        "Shows how MongoDB processes your query step-by-step.\n",
        "\n",
        "Helps identify whether the query uses:\n",
        "\n",
        "Indexes\n",
        "\n",
        "Collection scans\n",
        "\n",
        "Filters, sorts, etc.\n",
        "\n",
        "Performance Tuning\n",
        "Pinpoint slow queries and understand the reason.\n",
        "\n",
        "Helps in index optimization and query restructuring.\n",
        "\n",
        "Check Index Usage\n",
        "Reveals whether the query is using the best possible index.\n",
        "\n",
        "Prevents unnecessary collection scans (COLLSCAN).\n",
        "\n",
        "Debugging Queries\n",
        "Especially helpful when:\n",
        "\n",
        "Queries return no results\n",
        "\n",
        "Queries are unexpectedly slow\n",
        "\n",
        "You want to test before applying indexes\n",
        "\n",
        "\n",
        "Q12. How does MongoDB handle schema validation?\n",
        "-  How Does MongoDB Handle Schema Validation?\n",
        "Although MongoDB is schema-less by default, it supports schema validation to enforce rules on the structure and content of documents in a collection — similar to defining schemas in SQL databases.This helps ensure data quality, consistency, and integrity while retaining MongoDB’s flexibility.\n",
        "1. Using JSON Schema Validation\n",
        "- MongoDB uses JSON Schema (a standard schema format) to define validation rules.\n",
        "- You can:\n",
        " - Enforce required fields\n",
        " - Specify data types\n",
        " - Limit values (enums, ranges)\n",
        " - Apply nested rules for embedded documents\n",
        "- Example: Schema Validation\n",
        " - db.createCollection(\"students\", {\n",
        "   - validator: {\n",
        "      - $jsonSchema: {\n",
        "      - bsonType: \"object\",\n",
        "      - required: [\"name\", \"age\", \"email\"],\n",
        "      - properties: {\n",
        "        - name: {\n",
        "          - bsonType: \"string\",\n",
        "          - description: \"must be a string and is required\"\n",
        "        - },\n",
        "        - age: {\n",
        "          - bsonType: \"int\",\n",
        "          - minimum: 18,\n",
        "          - description: \"must be an integer >= 18\"\n",
        "        - },\n",
        "        - email: {\n",
        "          - bsonType: \"string\",\n",
        "          - pattern: \"^.+@.+$\",\n",
        "          - description: \"must be a valid email\"\n",
        "        - }\n",
        "      - }\n",
        "    - }\n",
        "  - }\n",
        "- });\n",
        "- This ensures:\n",
        "- Every document has name, age, and email\n",
        "age must be ≥ 18\n",
        "email must match email format\n",
        "2. Validation Levels\n",
        "- MongoDB lets you define how strictly the schema should be applied:\n",
        " - Level\tDescription\n",
        " - strict\tDocuments must fully follow the schema\n",
        " - moderate\tOnly validated if the document includes the validated fields\n",
        "off\tNo schema enforcement (default behavior)\n",
        " - validationLevel: \"strict\" // or \"moderate\", \"off\"\n",
        "3. Validation Actions\n",
        "- error (default): Reject documents that violate the schema\n",
        "- warn: Allow invalid documents but log a warning\n",
        "- validationAction: \"error\" // or \"warn\"\n",
        "4. Updating Validation on Existing Collection\n",
        "- db.runCommand({\n",
        "  - collMod: \"students\",\n",
        "  - validator: { ... },\n",
        "  - validationLevel: \"strict\",\n",
        "  - validationAction: \"error\"\n",
        "- });\n",
        "5. Disabling Schema Validation (optional)\n",
        "- If you want to allow all kinds of documents:\n",
        "- db.createCollection(\"flexible\", {\n",
        "  - validator: {}\n",
        "- });\n",
        "\n",
        "\n",
        "\n",
        "Q13. What is the difference between a primary and a secondary node in a replica set?\n",
        "1. Role in the Replica Set\n",
        "- Primary Node : Handles all write and read operations (by default) in the replica set.Only one primary exists at a time.\n",
        "- Secondary Node : Replicates data from the primary node.Can handle read operations (if read preference is set).Multiple secondaries can exist.\n",
        "2. Data Handling\n",
        "- Primary Node : All data changes (insert, update, delete) are written here first.\n",
        "- Secondary Node : Receives copies of operations from the primary via the oplog and applies them.\n",
        "3. Election and Failover\n",
        "- Primary Node : If it fails, the replica set holds an election to promote a secondary.\n",
        "- Secondary Node : Can be elected to become primary during failover (if eligible and up-to-date).\n",
        "4. Read/Write Access\n",
        "- Primary Node : Supports read and write operations.\n",
        "- Secondary Node : Only supports reads (and only if read preference is configured).Writes are not allowed unless it becomes the new primary.\n",
        "5. Usage in High Availability\n",
        "- Primary Node : Main point of data access and control. Needs to be reliable.\n",
        "- Secondary Node :\n",
        " - Used for:\n",
        "  - High availability\n",
        "  -  Disaster recovery\n",
        "  - Read scaling\n",
        "  - Backups (to reduce primary load)\n",
        "6. Priority Control\n",
        "- Primary Node:Highest priority node in elections (default unless manually set).\n",
        "- Secondary Node:Can have priority set to 0 to make it unelectable (e.g., archive backups).\n",
        "\n",
        "\n",
        "Q14. What security mechanisms does MongoDB provide for data protection?\n",
        "1. Authentication\n",
        "- Verifies the identity of users and applications connecting to the database.\n",
        "-  Supported methods:\n",
        " - SCRAM (default) – Secure challenge-response authentication\n",
        " - LDAP – Integrate with corporate identity systems\n",
        " - x.509 Certificates – For SSL-based client authentication\n",
        " - Kerberos – Enterprise-level authentication (e.g., Active Directory)\n",
        "2. Authorization (Role-Based Access Control - RBAC)\n",
        "- Determines what users are allowed to do.\n",
        "- You can define custom roles with specific privileges on:\n",
        " - Collections\n",
        " - Databases\n",
        " - Admin operations\n",
        "- Example:\n",
        " - db.createUser({\n",
        "   - user: \"analyst\",\n",
        "   - pwd: \"pass123\",\n",
        "   - roles: [{ role: \"read\", db: \"sales\" }]\n",
        " - });\n",
        "3. Encryption\n",
        "- In Transit (TLS/SSL):\n",
        " - Encrypts data sent between clients and MongoDB servers to prevent eavesdropping.\n",
        "- At Rest (Encryption on Disk):\n",
        " - Uses AES-256 encryption to protect data stored on disk.\n",
        " - Requires MongoDB Enterprise or MongoDB Atlas.\n",
        " - Supports KMIP (Key Management Interoperability Protocol) for external key storage.\n",
        "4. Auditing\n",
        "- Tracks who did what and when in your database.\n",
        "- Useful for compliance (GDPR, HIPAA, etc.)\n",
        "- Captures:\n",
        " - Login attempts\n",
        " - Role changes\n",
        " - Query operations\n",
        " - Administrative actions\n",
        "5. IP Whitelisting & Network Security\n",
        "- Limit access to MongoDB servers using:\n",
        "- IP whitelisting\n",
        "- VPC (Virtual Private Cloud) peering\n",
        "- Firewalls and network rules\n",
        "- MongoDB Atlas lets you easily control which IPs or services can connect.\n",
        "6. Field-Level Encryption (FLE)\n",
        "- Client-side encryption of specific fields before data even reaches MongoDB.\n",
        "- Only clients with the correct decryption keys can view sensitive fields (like passwords, card numbers).\n",
        "7. User & Role Separation\n",
        "- You can create:\n",
        " - Admin users\n",
        " - Read-only users\n",
        " - App users with limited access\n",
        " - And more – according to least privilege principle.\n",
        "8. Secure Defaults in MongoDB Atlas\n",
        "- Atlas (MongoDB’s cloud service) includes\n",
        "- Default TLS\n",
        "- Authentication required\n",
        "- Encryption at rest\n",
        "- Built-in backup and monitoring\n",
        "\n",
        "\n",
        "\n",
        "Q15.Explain the concept of embedded documents and when they should be used?\n",
        "- In MongoDB, embedded documents (also called nested documents) are documents that are stored within other documents — kind of like having a mini-document inside a larger one.This is a key feature of MongoDB’s document-oriented model, allowing you to store related data together.\n",
        "- Example:\n",
        " - A user with multiple addresses:\n",
        " - {\n",
        "   - \"_id\": 1,\n",
        "   - \"name\": \"Aarav\",\n",
        "   - \"email\": \"aarav@example.com\",\n",
        "   - \"addresses\": [\n",
        "     - { \"type\": \"home\", \"city\": \"Delhi\", \"pincode\": 110001 },\n",
        "     - { \"type\": \"work\", \"city\": \"Gurgaon\", \"pincode\": 122001 }\n",
        "    - ]\n",
        " - }\n",
        "- Here, the addresses field contains embedded documents.\n",
        "- When to Use Embedded Documents\n",
        " - Use embedded documents when you want to store related data together, and when:\n",
        "1. One-to-Few Relationships\n",
        "- Example: A user has a few phone numbers or emails.\n",
        "- Good use case for embedding.\n",
        "2. Data is Accessed Together\n",
        "- If you often read or write the main document and its nested data together (e.g., order + items).\n",
        "- Embedding avoids joins and speeds up queries.\n",
        "3. High Read Performance is Needed\n",
        "- Embedding keeps related data in a single document, which means:\n",
        "- Fewer disk I/O operations\n",
        "- Faster reads\n",
        "4. Data is Not Updated Frequently or Independently\n",
        "- Embedded data should not require frequent or independent updates.\n",
        "- If it does, separate collections might be better.\n",
        "- When NOT to Use Embedded Documents\n",
        "- Avoid embedding when:\n",
        " - The nested data grows without bounds (risk of exceeding MongoDB's 16MB document limit)\n",
        " - You have a many-to-many or one-to-many with high cardinality relationship\n",
        " - Embedded data is frequently queried or updated separately\n",
        "\n",
        "\n",
        "Q16.What is the purpose of MongoDB’s $lookup stage in aggregation?\n",
        "- The $lookup stage in MongoDB’s aggregation pipeline is used to perform a left outer join between documents in the current collection and documents from another collection.It allows you to combine related data from multiple collections, similar to a SQL JOIN.\n",
        "- Key Benefits of $lookup:\n",
        " - Joins Without SQL\n",
        " - Allows SQL-style joins in a NoSQL database like MongoDB.\n",
        " - Combines Related Data\n",
        " - Easily bring together data from multiple collections (e.g., users and orders).\n",
        " - Powerful in Reporting and Analytics\n",
        " - Ideal for building dashboards, summaries, and data views.\n",
        "\n",
        "\n",
        "Q17.What are some common use cases for MongoDB?\n",
        "1. Content Management Systems (CMS)\n",
        "- Why MongoDB? Flexible schema supports dynamic content (e.g., blog posts, product pages, metadata).\n",
        "- Example: WordPress-like systems, news websites, headless CMS platforms.\n",
        "2. Real-Time Analytics and Big Data Applications\n",
        "- Why MongoDB? Can handle high write throughput, large datasets, and real-time aggregation.\n",
        "- Example: Dashboards for financial analytics, IoT sensor tracking, and operational monitoring.\n",
        "3. Catalogs and E-commerce Platforms\n",
        "- Why MongoDB? Schema flexibility allows for different product types with varying attributes.\n",
        "- Example: Online stores, product listings, marketplaces like Amazon or Flipkart.\n",
        "4. Internet of Things (IoT)\n",
        "- Why MongoDB? Handles high-velocity data ingestion from devices and sensors.\n",
        "- Example: Smart home systems, health tracking wearables, industrial machines.\n",
        "5. Mobile and Web Applications\n",
        "- Why MongoDB? JSON-like documents map well to front-end data formats (like JavaScript objects).\n",
        "- Example: Social media apps, real-time messaging apps, ride-sharing platforms.\n",
        "6. User Profiles and Personalization\n",
        "- Why MongoDB? Easily stores diverse and evolving user data, preferences, and activity logs.\n",
        "- Example: Netflix recommendations, Spotify listening history, user dashboards.\n",
        "7. Gaming Applications\n",
        "- Why MongoDB? Supports rapid game state updates, player progress tracking, and leaderboards.\n",
        "- Example: Online multiplayer games, in-game inventory systems, player matching.\n",
        "8. Log and Event Data Storage\n",
        "- Why MongoDB? Optimized for write-heavy workloads and time-series data with flexible structure.\n",
        "- Example: Application logs, server events, security monitoring tools.\n",
        "9. Healthcare and Medical Records\n",
        "- Why MongoDB? Stores unstructured patient records, images, prescriptions, and test results.\n",
        "- Example: Electronic Health Records (EHR), telemedicine platforms.\n",
        "10. Distributed Applications / Microservices\n",
        "- Why MongoDB? Scales easily across regions and supports service-specific data models.\n",
        "- Example: Backend services in microservices architecture using MongoDB for data storage.\n",
        "\n",
        "\n",
        "\n",
        "Q18. What are the advantages of using MongoDB for horizontal scaling?\n",
        "1. Sharding for Data Distribution\n",
        "- What it means: MongoDB uses sharding to split data across multiple servers (called shards).\n",
        "- Advantage: Handles massive volumes of data by distributing the load.\n",
        "- Result: Increased storage capacity and better performance across a cluster.\n",
        "2. Linear Scalability\n",
        "- What it means: As your data or traffic grows, you can add more nodes.\n",
        "- Advantage: MongoDB scales linearly, meaning performance grows proportionally with each node.\n",
        "- Result: You avoid performance bottlenecks seen in vertically scaled (single-node) databases.\n",
        "3. High Availability\n",
        "- What it means: Each shard can have its own replica set.\n",
        "- Advantage: Even if one node fails, others continue serving data\n",
        "- Result: Ensures fault tolerance and business continuity.\n",
        "4. Cost-Effective Scaling\n",
        "- What it means: You can scale using commodity hardware or cloud instances.\n",
        "- Advantage: No need for expensive high-end servers.\n",
        "- Result: Great for startups and enterprise applications alike.\n",
        "5. Write and Read Scalability\n",
        "- What it means: Shards can handle write and read operations in parallel.\n",
        "- Advantage: Avoids single-write-node bottlenecks common in traditional databases.\n",
        "- Result: Faster write performance and distributed query load.\n",
        "6. Geo-Distribution Support\n",
        "- What it means: You can place shards in different geographic locations.\n",
        "- Advantage: Local users get faster responses.\n",
        "- Result: Better user experience and data sovereignty compliance.\n",
        "7. Automated Data Balancing\n",
        "- What it means: MongoDB’s balancer evenly distributes data across shards.\n",
        "- Advantage: Prevents hotspots or overloaded servers.\n",
        "- Result: Maintains consistent performance without manual intervention.\n",
        "\n",
        "\n",
        "Q19. How do MongoDB transactions differ from SQL transactions?\n",
        "1. Data Model\n",
        "- SQL Transactions:\n",
        " - Operate on structured tables with fixed schemas and relationships (rows, columns, foreign keys).\n",
        "- MongoDB Transactions:\n",
        " - Operate on JSON-like documents (BSON) in collections with flexible schemas and embedded documents.\n",
        "2. Multi-Document Transactions\n",
        "- SQL:\n",
        " - Supports multi-table (multi-row) transactions natively since the beginning.\n",
        "- MongoDB:\n",
        " - Introduced multi-document transactions in version 4.0 (for replica sets) and 4.2+ (for sharded clusters).\n",
        "3. Schema Enforcement\n",
        "- SQL:\n",
        " - Schema is strictly enforced (data types, constraints, foreign keys).\n",
        "- MongoDB:\n",
        " - Schema-less by default (unless you enable validation rules); transactions operate on flexible documents.\n",
        "4. Use Cases\n",
        "- SQL:\n",
        " - Ideal for highly structured, relational systems (e.g., banking, ERP).\n",
        "- MongoDB:\n",
        " - Best for document-based apps with denormalized data (e.g., content management, catalogs).\n",
        "5. Isolation and Concurrency Control\n",
        "- SQL:\n",
        " - Uses well-established isolation levels (READ COMMITTED, SERIALIZABLE, etc.) with locking mechanisms.\n",
        "- MongoDB:\n",
        " - Uses snapshot isolation with an oplog-based replication system. Not all isolation levels are supported.\n",
        "6. Performance Overhead\n",
        "- SQL:\n",
        " - Designed for heavy transaction use — optimized over decades.\n",
        "- MongoDB:\n",
        " - Transactions add overhead and are slower than single-document operations — which are atomic by default.\n",
        "7. Default Behavior\n",
        "- SQL:\n",
        " - Transactions are commonly required for most operations.\n",
        "- MongoDB:\n",
        " - Designed to work without transactions by leveraging atomic single-document writes and data embedding.\n",
        "\n",
        "\n",
        "Q20.What are the main differences between capped collections and regular collections?\n",
        "1. Storage Size and Document Limit\n",
        "- Regular Collection:\n",
        " - No fixed size limit.\n",
        " - Grows dynamically as more documents are added.\n",
        "- Capped Collection:\n",
        " - Has a fixed size (in bytes or number of documents).\n",
        " - When the limit is reached, oldest documents are overwritten (FIFO behavior).\n",
        "2. Insertion Behavior\n",
        "- Regular Collection:\n",
        " - Allows insertions anywhere; documents can be updated, deleted, or inserted freely.\n",
        "- Capped Collection:\n",
        " - Only supports appending new documents.\n",
        " - No deletion of individual documents (automatically handled by overwriting).\n",
        " - No reordering or resizing of documents.\n",
        "3. Use Cases\n",
        "- Regular Collection:\n",
        " - General-purpose use (e.g., user data, products, orders).\n",
        "- Capped Collection:\n",
        " - Ideal for logging, caching, or sensor data, where:\n",
        " - You only need recent data\n",
        " - Order of insertion matters\n",
        "4. Performance\n",
        "- Regular Collection:\n",
        " - Performance varies based on indexing, document size, and queries.\n",
        "- Capped Collection:\n",
        " - Faster write performance due to:\n",
        "  - Pre-allocated space\n",
        "  - No document relocation\n",
        "  - Simpler storage pattern\n",
        "5. Document Updates\n",
        "- Regular Collection:\n",
        " - Allows updates that change document size\n",
        "- Capped Collection:\n",
        " - Only allows updates that don’t increase document size.\n",
        " - If updated size is larger, operation will fail.\n",
        "6. Document Ordering\n",
        "- Regular Collection:\n",
        " - No guarantee of insertion order unless explicitly sorted.\n",
        "- Capped Collection:\n",
        " - Maintains natural insertion order (important for logs).\n",
        "\n",
        "\n",
        "Q21.What is the purpose of the $match stage in MongoDB’s aggregation pipeline?\n",
        "- The $match stage is used to filter documents in the aggregation pipeline, similar to how the WHERE clause works in SQL.It passes only those documents that meet the specified condition(s) to the next stage in the pipeline.\n",
        "- Why Use $match?\n",
        " - Filter Data Early\n",
        " - Reduces the number of documents passed through the pipeline, improving performance.\n",
        "- Works with All Query Operators\n",
        " - Supports all the same operators as .find(), like $gt, $lt, $in, $and, etc.\n",
        " - Used in Combination with Other Stages\n",
        " - Commonly used before grouping ($group), sorting ($sort), or projecting ($project) data\n",
        "\n",
        "\n",
        "Q22. How can you secure access to a MongoDB database?\n",
        "1. Enable Authentication\n",
        "- Purpose: Requires users to log in before accessing the database.\n",
        "- How: Start MongoDB with authentication enabled.\n",
        " - mongod --auth --port 27017 --dbpath /data/db\n",
        " - Create Admin User:\n",
        " - use admin\n",
        " - db.createUser({\n",
        "  - user: \"admin\",\n",
        "  - pwd: \"securepassword\",\n",
        "  - roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ]\n",
        "- });\n",
        "2. Use Role-Based Access Control (RBAC)\n",
        "- Purpose: Assigns specific privileges to users.\n",
        "- How: Create users with appropriate roles (e.g., readOnly, dbAdmin, readWrite).\n",
        "- db.createUser({\n",
        "  - user: \"analyst\",\n",
        "  - pwd: \"analyst123\",\n",
        "  -  roles: [{ role: \"read\", db: \"sales\" }]\n",
        "- });\n",
        "3. Enable TLS/SSL Encryption (For Data in Transit)\n",
        "- Purpose: Encrypts data transmitted between MongoDB clients and servers.\n",
        "- How:\n",
        "- Generate SSL certificates.\n",
        "- Start MongoDB with SSL options:\n",
        "- mongod --sslMode requireSSL --sslPEMKeyFile /etc/ssl/mongodb.pem\n",
        "4. Use Encryption at Rest\n",
        "- Purpose: Protects stored data on disk.\n",
        "- How:\n",
        " - Available in MongoDB Enterprise Edition and Atlas.\n",
        " - Uses AES-256 encryption.\n",
        " - Supports integration with external Key Management Systems (KMS).\n",
        "5. Network Access Control (IP Whitelisting)\n",
        "- Purpose: Limits access to trusted IP addresses only.\n",
        "- How (MongoDB Atlas):\n",
        " - Configure IP whitelist in the Network Access settings.\n",
        "- How (Self-Hosted):\n",
        " - Use firewall rules (e.g., iptables, ufw) to restrict port 27017.\n",
        "6. Bind MongoDB to Localhost or Specific IP\n",
        "- Purpose: Prevents open access to the entire internet.\n",
        "- How:\n",
        " - Set bind IP in the config file (mongod.conf):\n",
        "- net:\n",
        "  - bindIp: 127.0.0.1\n",
        "7. Use Strong Passwords and Change Them Regularly\n",
        "- Purpose: Prevent brute-force attacks.\n",
        "- How: Use password managers or environment variables; enforce password complexity.\n",
        "8. Enable Auditing\n",
        "- Purpose: Track who did what and when (compliance and forensic tracking).\n",
        "- How: Available in MongoDB Enterprise Edition.\n",
        "- Logs: Authentication attempts, role changes, CRUD operations, etc.\n",
        "9. Regular Backups & Security Patching\n",
        "- Purpose: Protect against data loss and vulnerabilities.\n",
        "- How:\n",
        "- Use mongodump, Atlas backups, or Ops Manager.\n",
        "- Regularly update MongoDB to the latest version with security patches.\n",
        "10. Use MongoDB Atlas (Cloud) for Built-in Security\n",
        "- Comes with:\n",
        " - TLS enabled by default\n",
        " - IP access control\n",
        " - Encryption at rest\n",
        " - Backup automation\n",
        " - 2FA for user accounts\n",
        "\n",
        "\n",
        "\n",
        "Q23 What is MongoDB’s WiredTiger storage engine, and why is it important?\n",
        "-  WiredTiger is the default storage engine used by MongoDB (since version 3.2+), responsible for how data is stored, managed, and accessed on disk.It's a high-performance, modern storage engine designed to handle large-scale, high-throughput applications.\n",
        "- Importance :\n",
        "1. Document-Level Concurrency\n",
        "- Allows multiple write operations on different documents at the same time.\n",
        "- Increases performance for high-concurrency applications.\n",
        "2. Data Compression\n",
        "- Compresses both data and indexes (default: Snappy).\n",
        "- Saves disk space and reduces disk I/O.\n",
        "3. Efficient Caching\n",
        "- Uses a memory-efficient cache for frequently accessed data.\n",
        "- Speeds up read operations significantly.\n",
        "4. Durability with Journaling\n",
        "- Uses a write-ahead log (journal) to recover from crashes.\n",
        "- Ensures data is not lost during unexpected shutdowns.\n",
        "5. Checkpointing\n",
        "- Periodically creates checkpoints of data.\n",
        "- Enables faster recovery and consistency after crashes.\n",
        "6. ACID Compliance\n",
        "- Supports Atomicity, Consistency, Isolation, and Durability for transactions.\n",
        "- Ensures data reliability in critical applications.\n",
        "7. Tunable Performance\n",
        "- Developers can customize settings (e.g., cache size, compression type).\n",
        "- Adapts well to various workloads like read-heavy or write-heavy apps.\n",
        "8. Scalability\n",
        "- Designed to support large datasets and high-throughput operations.\n",
        "- Suitable for everything from small apps to enterprise systems.\n",
        "9. Default and Actively Supported\n",
        "- WiredTiger is the default engine in MongoDB (since v3.2+).\n",
        "- All modern MongoDB features are optimized for WiredTiger."
      ],
      "metadata": {
        "id": "WvFfmzH185NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas pymongo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzJ_Vh_JYKpO",
        "outputId": "c2558527-6593-4c05-c74a-92de2f3c6db0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3.Count and display the total number of documents in the Orders collection\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Count the documents\n",
        "total_docs = collection.count_documents({})\n",
        "\n",
        "# Step 3: Display the count\n",
        "print(f\"📦 Total number of documents in 'orders' collection: {total_docs}\")\n"
      ],
      "metadata": {
        "id": "FE-f3M84ZWSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4.Write a query to fetch all orders from the \"West\" region\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Query for orders from the \"West\" region\n",
        "west_orders = collection.find({ \"Region\": \"West\" })\n",
        "\n",
        "# Step 3: Print the results\n",
        "for order in west_orders:\n",
        "    print(order)\n"
      ],
      "metadata": {
        "id": "xfrDMFbeZb4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5.Write a query to find orders where Sales is greater than 500\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Query: Find orders where Sales > 500\n",
        "high_sales_orders = collection.find({ \"Sales\": { \"$gt\": 500 } })\n",
        "\n",
        "# Print the results\n",
        "for order in high_sales_orders:\n",
        "    print(order)\n"
      ],
      "metadata": {
        "id": "fXjHT0k9ZjAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6. Fetch the top 3 orders with the highest Profit\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Query - Sort by Profit descending, limit to 3\n",
        "top_profit_orders = collection.find().sort(\"Profit\", -1).limit(3)\n",
        "\n",
        "# Step 3: Print the results\n",
        "for order in top_profit_orders:\n",
        "    print(order)\n"
      ],
      "metadata": {
        "id": "_zhin6XZZpmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7.Update all orders with Ship Mode as \"First Class\" to \"Premium Class\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Update Ship Mode from \"First Class\" to \"Premium Class\"\n",
        "result = collection.update_many(\n",
        "    { \"Ship Mode\": \"First Class\" },          # Filter condition\n",
        "    { \"$set\": { \"Ship Mode\": \"Premium Class\" } }  # Update action\n",
        ")\n",
        "\n",
        "# Step 3: Display result\n",
        "print(f\"✅ Modified {result.modified_count} documents.\")\n"
      ],
      "metadata": {
        "id": "mMEI70SIZylK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8. Delete all orders where Sales is less than 50\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Delete orders where Sales < 50\n",
        "result = collection.delete_many({ \"Sales\": { \"$lt\": 50 } })\n",
        "\n",
        "# Step 3: Display result\n",
        "print(f\"🗑️ Deleted {result.deleted_count} documents where Sales < 50.\")\n"
      ],
      "metadata": {
        "id": "OUA1SxmkZ6uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q9.Use aggregation to group orders by Region and calculate total sales per region\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Define aggregation pipeline\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$Region\",               # Group by Region\n",
        "            \"total_sales\": { \"$sum\": \"$Sales\" }  # Sum of Sales per Region\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$sort\": { \"total_sales\": -1 }      # Optional: sort by sales descending\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 3: Execute aggregation\n",
        "results = collection.aggregate(pipeline)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"📊 Total Sales by Region:\")\n",
        "for result in results:\n",
        "    print(f\"Region: {result['_id']}, Total Sales: {round(result['total_sales'], 2)}\")\n"
      ],
      "metadata": {
        "id": "mqJ6VCLsaI6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q10. Fetch all distinct values for Ship Mode from the collection\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Get distinct Ship Mode values\n",
        "distinct_ship_modes = collection.distinct(\"Ship Mode\")\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"🚚 Distinct Ship Modes:\")\n",
        "for mode in distinct_ship_modes:\n",
        "    print(f\"- {mode}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "I4NsWQo_aQ_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q11.Count the number of orders for each category.\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Define aggregation pipeline\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$Category\",         # Group by Category\n",
        "            \"order_count\": { \"$sum\": 1 }  # Count each order\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$sort\": { \"order_count\": -1 }   # Optional: sort by count descending\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 3: Execute aggregation\n",
        "results = collection.aggregate(pipeline)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"📦 Number of Orders by Category:\")\n",
        "for result in results:\n",
        "    print(f\"Category: {result['_id']}, Orders: {result['order_count']}\")\n"
      ],
      "metadata": {
        "id": "QiymPYdQaZJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1.Write a Python script to load the Superstore dataset from a CSV file into MongoDB\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Load the CSV file into a pandas DataFrame\n",
        "file_path = '/mnt/data/superstore.csv'  # Update this path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Optional - Convert column names to remove spaces (MongoDB-friendly)\n",
        "df.columns = df.columns.str.replace(' ', '_')\n",
        "\n",
        "# Step 3: Convert DataFrame to dictionary format\n",
        "records = df.to_dict(orient='records')\n",
        "\n",
        "# Step 4: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")  # Adjust if using remote MongoDB\n",
        "db = client[\"superstore_db\"]                        # Database name\n",
        "collection = db[\"orders\"]                           # Collection name\n",
        "\n",
        "# Step 5: Insert data into MongoDB\n",
        "collection.insert_many(records)\n",
        "\n",
        "# Step 6: Print result\n",
        "print(f\"✅ Inserted {len(records)} documents into 'orders' collection in 'superstore_db' database.\")\n"
      ],
      "metadata": {
        "id": "vEITPLcPah5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2. Retrieve and print all documents from the Orders collection\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Step 1: Connect to MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"superstore_db\"]\n",
        "collection = db[\"orders\"]\n",
        "\n",
        "# Step 2: Fetch all documents from the collection\n",
        "all_orders = collection.find()\n",
        "\n",
        "# Step 3: Print each document\n",
        "for order in all_orders:\n",
        "    print(order)\n"
      ],
      "metadata": {
        "id": "5zUYn3tUaqlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}